import torch 
import torch.nn as nn 
import torch.nn.functional as F

def scaled_dot_product():
    pass 

class scalable_softmax(nn.Module):
    pass 

class MultiHeadAttention(nn.Module):
    pass 

class PositionalEncoding(nn.Module):
    pass 

class TransformerLayer(nn.Module):
    pass 

class Transformer(nn.Module):
    pass 

